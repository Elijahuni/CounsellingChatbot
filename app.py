import streamlit as st
from data_processor import DataProcessor
from rag_engine import RAGEngine
from db_handler import DatabaseHandler
from location_service import LocationService
import json
import pandas as pd
import os

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="AI ì‹¬ë¦¬ ìƒë‹´ ì±—ë´‡",
    page_icon="ğŸ¤—",
    layout="wide"
)

# ë°ì´í„° í”„ë¡œì„¸ì„œ ë° RAG ì—”ì§„ ì´ˆê¸°í™”
@st.cache_resource(show_spinner=True)
def initialize_rag():
    try:
        data_processor = DataProcessor()
        
        # ë°ì´í„° íŒŒì¼ ê²½ë¡œ
        single_turn_file = "total_kor_counsel_bot.jsonl"
        multi_turn_file = "total_kor_multiturn_counsel_bot.jsonl"
        wellness_file = "wellness.csv"
        
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        available_files = []
        for file_path in [single_turn_file, multi_turn_file, wellness_file]:
            if os.path.exists(file_path):
                available_files.append(file_path)
            
        if not available_files:
            st.error("ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        st.info(f"ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„° íŒŒì¼: {', '.join(available_files)}")
        
        # Initialize counseling_data list if not exists
        if not hasattr(data_processor, 'counseling_data') or not data_processor.counseling_data:
            data_processor.counseling_data = []
            
            # ì‹±ê¸€í„´ ë°ì´í„° ë¡œë“œ
            if os.path.exists(single_turn_file):
                try:
                    with open(single_turn_file, 'r', encoding='utf-8') as f:
                        lines = f.readlines()
                        progress_bar = st.progress(0)
                        
                        for i, line in enumerate(lines):
                            try:
                                data = json.loads(line.strip())
                                data_processor.counseling_data.append({
                                    'input': data['input'],
                                    'output': data['output'],
                                    'type': 'single'
                                })
                                progress_bar.progress((i + 1) / len(lines))
                            except json.JSONDecodeError:
                                continue
                    st.success(f"ì‹±ê¸€í„´ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {sum(1 for d in data_processor.counseling_data if d['type'] == 'single')}ê°œ")
                except Exception as e:
                    st.error(f"ì‹±ê¸€í„´ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}")

            # ë©€í‹°í„´ ë°ì´í„° ë¡œë“œ
            if os.path.exists(multi_turn_file):
                try:
                    with open(multi_turn_file, 'r', encoding='utf-8') as f:
                        lines = f.readlines()
                        for line in lines:
                            try:
                                dialogue_data = json.loads(line.strip())
                                if isinstance(dialogue_data, list):
                                    processed_input = ""
                                    processed_output = ""
                                    current_speaker = None
                                    current_utterance = ""
                                    
                                    for turn in dialogue_data:
                                        speaker = turn.get('speaker', '')
                                        utterance = turn.get('utterance', '')
                                        
                                        if current_speaker and current_speaker != speaker:
                                            if current_speaker == "ë‚´ë‹´ì":
                                                processed_input += f"{current_utterance}\n"
                                            else:
                                                processed_output += f"{current_utterance}\n"
                                            current_utterance = f"{utterance}"
                                        else:
                                            current_utterance += f" {utterance}"
                                        
                                        current_speaker = speaker
                                    
                                    if current_speaker == "ë‚´ë‹´ì":
                                        processed_input += f"{current_utterance}\n"
                                    else:
                                        processed_output += f"{current_utterance}\n"
                                    
                                    if processed_input.strip() and processed_output.strip():
                                        data_processor.counseling_data.append({
                                            'input': processed_input.strip(),
                                            'output': processed_output.strip(),
                                            'type': 'multi'
                                        })
                            except (json.JSONDecodeError, KeyError) as e:
                                continue
                    
                    st.success(f"ë©€í‹°í„´ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {sum(1 for d in data_processor.counseling_data if d['type'] == 'multi')}ê°œ")
                except Exception as e:
                    st.error(f"ë©€í‹°í„´ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}")

            # Wellness ë°ì´í„° ë¡œë“œ ë¶€ë¶„ ìˆ˜ì •
            if os.path.exists(wellness_file):
                try:
                    # CSV íŒŒì¼ ë¡œë“œ
                    wellness_df = pd.read_csv(wellness_file, encoding='utf-8')
                    
                    # ì»¬ëŸ¼ëª… ì²´í¬ ë° ë°ì´í„° ì²˜ë¦¬
                    if 'ìœ ì €' in wellness_df.columns and 'ì±—ë´‡' in wellness_df.columns:
                        for _, row in wellness_df.iterrows():
                            if pd.notna(row['ìœ ì €']) and pd.notna(row['ì±—ë´‡']):
                                data_processor.counseling_data.append({
                                    'input': str(row['ìœ ì €']).strip(),
                                    'output': str(row['ì±—ë´‡']).strip(),
                                    'type': 'wellness',
                                    'category': row.get('êµ¬ë¶„', '')  # êµ¬ë¶„ ì •ë³´ë„ ì €ì¥
                                })
                        
                        wellness_count = sum(1 for d in data_processor.counseling_data if d['type'] == 'wellness')
                        if wellness_count > 0:
                            st.success(f"Wellness ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {wellness_count}ê°œ")
                            
                        else:
                            st.warning("ìœ íš¨í•œ Wellness ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        st.warning("CSV íŒŒì¼ì˜ í•„ìˆ˜ ì»¬ëŸ¼(ìœ ì €, ì±—ë´‡)ì´ ì—†ìŠµë‹ˆë‹¤.")
                        
                except Exception as e:
                    st.warning(f"Wellness ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                    st.write("CSV íŒŒì¼ êµ¬ì¡°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”. (í•„ìš”í•œ ì»¬ëŸ¼: êµ¬ë¶„, ìœ ì €, ì±—ë´‡)")

            # FAISS ì¸ë±ìŠ¤ ìƒì„± ë˜ëŠ” ë¡œë“œ
            if os.path.exists("faiss_index.idx"):
                data_processor.load_index("faiss_index.idx")
                st.success("ê¸°ì¡´ ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ")
            else:
                if data_processor.create_embeddings():
                    data_processor.save_index("faiss_index.idx")
                else:
                    st.error("ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨")
                    return None

        # ë°ì´í„° ë¡œë“œ ìƒíƒœ í‘œì‹œ
        total_data = len(data_processor.counseling_data)
        single_turn_count = sum(1 for d in data_processor.counseling_data if d.get('type') == 'single')
        multi_turn_count = sum(1 for d in data_processor.counseling_data if d.get('type') == 'multi')
        wellness_count = sum(1 for d in data_processor.counseling_data if d.get('type') == 'wellness')
        
        st.success(f"""
        ğŸ“Š ë°ì´í„° í˜„í™©:
        - ì‹±ê¸€í„´ ë°ì´í„°: {single_turn_count}ê°œ
        - ë©€í‹°í„´ ë°ì´í„°: {multi_turn_count}ê°œ
        - Wellness ë°ì´í„°: {wellness_count}ê°œ
        - ì´ ë°ì´í„°: {total_data}ê°œ
        """)
        
        # RAG ì—”ì§„ ì´ˆê¸°í™”
        rag_engine = RAGEngine(data_processor, st.secrets["OPENAI_API_KEY"])
        return rag_engine
        
    except Exception as e:
        st.error(f"ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

# ìœ„í—˜ ìƒí™© ê°ì§€ í•¨ìˆ˜
def detect_crisis(text: str) -> bool:
    crisis_keywords = [
        # ìí•´/ìì‚´ ê´€ë ¨
        'ìì‚´', 'ì£½ê³ ì‹¶ë‹¤', 'ì£½ì„ë˜', 'ìí•´', 
        
        # í­ë ¥ ê´€ë ¨
        'ì‚´ì¸', 'ì‚´í•´', 'íƒ€ì‚´', 'í•™ëŒ€',
        
        # ìœ„í—˜ ë„êµ¬ ê´€ë ¨
        'ë†ì•½', 'ìˆ˜ë©´ì œ', 'ì²­ì‚°ê°€ë¦¬', 
        
        # ê·¹ë‹¨ì  ìƒí™©
        'ëª©ìˆ¨', 'ìœ ì„œ', 'ì‹œì²´',
        
        # ì‹¬ê°í•œ ë²”ì£„
        'ë§ˆì•½', 'í­í–‰', 'ì„±í­ë ¥', 'ê°ê¸ˆ'
    ]
    return any(keyword in text for keyword in crisis_keywords)

# ì „ë¬¸ê°€ ì—°ê³„ ì •ë³´
CRISIS_RESOURCES = """
ğŸš¨ ì „ë¬¸ê°€ì˜ ë„ì›€ì´ í•„ìš”í•´ ë³´ì…ë‹ˆë‹¤.

ê¸´ê¸‰ ì—°ë½ì²˜:
ğŸ“ ìì‚´ì˜ˆë°©ìƒë‹´ì „í™”: 1393
ğŸ“ ì •ì‹ ê±´ê°•ìƒë‹´ì „í™”: 1577-0199
"""

def main():
    # ë°ì´í„°ë² ì´ìŠ¤ í•¸ë“¤ëŸ¬ ì´ˆê¸°í™”
    if 'db_handler' not in st.session_state:
        st.session_state.db_handler = DatabaseHandler()
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'initialized' not in st.session_state:
        st.session_state.initialized = False
        st.session_state.messages = []
        # ìƒˆë¡œìš´ ëŒ€í™” ì„¸ì…˜ ìƒì„±
        st.session_state.current_session_id = st.session_state.db_handler.create_session()
    
    # RAG ì—”ì§„ ì´ˆê¸°í™”
    if not st.session_state.initialized:
        with st.spinner("ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•˜ëŠ” ì¤‘..."):
            rag_engine = initialize_rag()
            if rag_engine:
                st.session_state.rag_engine = rag_engine
                st.session_state.initialized = True
            else:
                st.error("ì‹œìŠ¤í…œ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                return
    
    # ì œëª©
    st.title("ğŸ¤— AI ì‹¬ë¦¬ ìƒë‹´ ì±—ë´‡ ê³µê°ì—”ì§„")
    st.write("ì•ˆë…•í•˜ì„¸ìš”! AI ì‹¬ë¦¬ ìƒë‹´ ì±—ë´‡ ê³µê°ì—”ì§„ ì…ë‹ˆë‹¤. í¸ì•ˆí•œ ë§ˆìŒìœ¼ë¡œ ì´ì•¼ê¸°ë¥¼ ì‹œì‘í•´ì£¼ì„¸ìš”.")
    
    # ì±„íŒ… ì´ë ¥ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    if prompt := st.chat_input("ê³ ë¯¼ì´ë‚˜ ê°ì •ì„ ì´ì•¼ê¸°í•´ì£¼ì„¸ìš”..."):
        # ìœ„í—˜ ìƒí™© ê°ì§€
        crisis_detected = detect_crisis(prompt)
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
        st.session_state.db_handler.save_message(
            session_id=st.session_state.current_session_id,
            role="user",
            content=prompt,
            crisis_detected=crisis_detected
        )
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # ì‘ë‹µ ìƒì„±
        if crisis_detected:
            response = f"{st.session_state.rag_engine.get_response(prompt, st.session_state.messages)}\n\n{CRISIS_RESOURCES}"
        else:
            response = st.session_state.rag_engine.get_response(prompt, st.session_state.messages)
        
        # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì €ì¥
        st.session_state.db_handler.save_message(
            session_id=st.session_state.current_session_id,
            role="assistant",
            content=response,
            crisis_detected=crisis_detected
        )
        
        # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ í‘œì‹œ
        st.session_state.messages.append({"role": "assistant", "content": response})
        with st.chat_message("assistant"):
            st.markdown(response)
    
    # ì‚¬ì´ë“œë°” êµ¬ì„±
    with st.sidebar:
        st.header("ğŸ’­ ìƒë‹´ ì •ë³´")
        message_count = sum(1 for msg in st.session_state.messages if msg["role"] == "user")
        st.write("ğŸ’Œ ì „ì²´ ëŒ€í™” ìˆ˜:", message_count)
        
        # ëŒ€í™” ë‚´ë³´ë‚´ê¸° ë²„íŠ¼
        if st.button("ğŸ“¥ ëŒ€í™” ë‚´ë³´ë‚´ê¸°"):
            if st.session_state.current_session_id:
                export_data = st.session_state.db_handler.export_session_data(
                    st.session_state.current_session_id
                )
                if export_data:
                    st.download_button(
                        label="ğŸ’¾ JSON íŒŒì¼ë¡œ ì €ì¥",
                        data=export_data,
                        file_name=f"chat_session_{st.session_state.current_session_id}.json",
                        mime="application/json"
                    )
        
        # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
        if st.button("ğŸ”„ ëŒ€í™” ì´ˆê¸°í™”"):
            if st.session_state.current_session_id:
                # í˜„ì¬ ì„¸ì…˜ ì¢…ë£Œ
                st.session_state.db_handler.end_session(st.session_state.current_session_id)
                # ìƒˆë¡œìš´ ì„¸ì…˜ ì‹œì‘
                st.session_state.current_session_id = st.session_state.db_handler.create_session()
            st.session_state.messages = []
            st.experimental_rerun()
        
        with st.expander("â„¹ï¸ ì•ˆë‚´ì‚¬í•­"):
            st.write("""
            - ğŸ’ ì¼ìƒì ì¸ ê³ ë¯¼ ìƒë‹´ì„ ì œê³µí•©ë‹ˆë‹¤
            - ğŸ¥ ê¸´ê¸‰í•œ ìƒí™©ì€ ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì„¸ìš”
            - ğŸ”’ ëª¨ë“  ëŒ€í™”ëŠ” ë¹„ê³µê°œì…ë‹ˆë‹¤
            - ğŸ’¾ ëŒ€í™” ë‚´ìš©ì€ ë°ì´í„°ë² ì´ìŠ¤ì— ì•ˆì „í•˜ê²Œ ì €ì¥ë©ë‹ˆë‹¤
            """)
            
        # í†µê³„ ì •ë³´ í‘œì‹œ
        with st.expander("ğŸ“Š ìƒë‹´ í†µê³„"):
            if st.session_state.current_session_id:
                emotion_stats = st.session_state.db_handler.get_emotion_statistics(
                    st.session_state.current_session_id
                )
                if emotion_stats:
                    st.write("ê°ì • ë¶„ì„ ê²°ê³¼:")
                    for emotion, score in emotion_stats:
                        st.progress(float(score), text=f"{emotion}: {score:.2f}")
        # ì—¬ê¸°ì— ìœ„ì¹˜ ì„œë¹„ìŠ¤ ì¶”ê°€
        st.markdown("---")  # êµ¬ë¶„ì„  ì¶”ê°€
        st.header("ğŸ“ ì£¼ë³€ ìƒë‹´ì„¼í„° ì°¾ê¸°")
        location_service = LocationService()
        
        # ìœ„ì¹˜ ì…ë ¥ ë°›ê¸°
        location_data = location_service.get_location_input()
        
        if location_data:
            # ì§€ë„ í‘œì‹œ
            st.subheader("ğŸ—ºï¸ í˜„ì¬ ìœ„ì¹˜")
            location_service.show_map(location_data)
            
            # ì£¼ë³€ ìƒë‹´ì„¼í„° ê²€ìƒ‰
            st.subheader("ğŸ¥ ì£¼ë³€ ìƒë‹´ì„¼í„°")
            centers = location_service.find_nearby_counseling_centers(location_data)
            
            if centers:
                for center in centers:
                    with st.expander(f"ğŸ“ {center['name']}"):
                        st.write(f"ì£¼ì†Œ: {center['address']}")
                        st.write(f"ì „í™”: {center['phone']}")
                        st.write(f"ê±°ë¦¬: {center['distance']}")
            else:
                st.info("ì£¼ë³€ì— ìƒë‹´ì„¼í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
