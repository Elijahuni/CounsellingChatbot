# core/rag_engine.py
from typing import List, Dict
from core.data_processor import DataProcessor
from openai import OpenAI

class RAGEngine:
    def __init__(self, data_processor: DataProcessor, openai_api_key: str):
        self.data_processor = data_processor
        self.client = OpenAI(api_key=openai_api_key)
        
    def generate_context(self, query: str) -> str:
        """ìœ ì‚¬ ìƒë‹´ ì‚¬ë¡€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
        similar_cases = self.data_processor.find_similar_cases(query, k=2)  # ìœ ì‚¬ ì‚¬ë¡€ ìˆ˜ ì¡°ì •
        
        context = "ë‹¤ìŒì€ ìœ ì‚¬í•œ ìƒë‹´ ì‚¬ë¡€ë“¤ì…ë‹ˆë‹¤:\n\n"
        for i, case in enumerate(similar_cases, 1):
            context += f"ì‚¬ë¡€ {i}:\n"
            if case.get('type') == 'multi':  # ë©€í‹°í„´ ëŒ€í™”ì¸ ê²½ìš°
                context += f"ëŒ€í™” ë‚´ìš©:\n{case['input']}\nìƒë‹´ì‚¬ ë‹µë³€:\n{case['output']}\n\n"
            else:  # ì‹±ê¸€í„´ ëŒ€í™”ì¸ ê²½ìš°
                context += f"ë‚´ë‹´ì: {case['input']}\nìƒë‹´ì‚¬: {case['output']}\n\n"
            
        return context
    
    def get_response(self, query: str, chat_history: List[Dict]) -> str:
        """RAG ê¸°ë°˜ ì‘ë‹µ ìƒì„±"""
        try:
            # ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            context = self.generate_context(query)
            # íˆìŠ¤í† ë¦¬ ê¸¸ì´ë¡œ ëŒ€í™” ë‹¨ê³„ íŒŒì•…
            is_initial = len(chat_history) <= 2

            system_prompt = """ë‹¹ì‹ ì€ 10ë…„ ì´ìƒì˜ ê²½ë ¥ì„ ê°€ì§„ ì „ë¬¸ ì‹¬ë¦¬ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.
    ë‚´ë‹´ìì˜ ì´ì•¼ê¸°ì— ê¹Šì´ ìˆê²Œ ê·€ ê¸°ìš¸ì´ê³ , ê·¸ë“¤ì˜ ê°ì •ì„ ì„¬ì„¸í•˜ê²Œ ì´í•´í•˜ë©°,
    ì ì ˆí•œ ì‹œì ì— í†µì°°ë ¥ ìˆëŠ” ì§ˆë¬¸ê³¼ ë°˜ì˜ì„ ì œê³µí•©ë‹ˆë‹¤.

    ì „ë°˜ì ì¸ ìƒë‹´ ì›ì¹™:
    1. ê²½ì²­ê³¼ ê³µê°ì„ ìµœìš°ì„ ìœ¼ë¡œ í•©ë‹ˆë‹¤
    2. ë‚´ë‹´ìì˜ í˜ì´ìŠ¤ì— ë§ì¶° ëŒ€í™”ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤
    3. í•œ ë²ˆì— í•œ ê°€ì§€ ì£¼ì œë§Œ ê¹Šì´ ìˆê²Œ ë‹¤ë£¹ë‹ˆë‹¤
    4. íŒë‹¨ì´ë‚˜ í‰ê°€ëŠ” ì ˆëŒ€ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤

    ì¸ì‚¬ ê·œì¹™:
    1. ì²« ì¸ì‚¬:
    - "ì•ˆë…•" ë˜ëŠ” "ì•ˆë…•í•˜ì„¸ìš”" ì…ë ¥ ì‹œ ë°˜ë“œì‹œ:
    "ì•ˆë…•í•˜ì„¸ìš”! AI ì‹¬ë¦¬ ìƒë‹´ ì±—ë´‡ ê³µê°ì—”ì§„ì…ë‹ˆë‹¤. í¸ì•ˆí•œ ë§ˆìŒìœ¼ë¡œ ì´ì•¼ê¸°ë¥¼ ì‹œì‘í•´ì£¼ì„¸ìš”."
    2. ë§ˆì§€ë§‰ ì¸ì‚¬:
    - ë‹¤ë¥¸ í˜•ì‹ ì‚¬ìš©: "í•¨ê»˜ ì´ì•¼ê¸° ë‚˜ëˆŒ ìˆ˜ ìˆì–´ ì¢‹ì•˜ìŠµë‹ˆë‹¤. ì–¸ì œë“  ë„ì›€ì´ í•„ìš”í•˜ì‹œë‹¤ë©´ ë‹¤ì‹œ ì°¾ì•„ì£¼ì„¸ìš”. ì‘ì›í•˜ê² ìŠµë‹ˆë‹¤. ğŸ˜Š"

    ëŒ€í™” íŒ¨í„´:
    1. ì‹±ê¸€í„´ ì‘ë‹µ:
    - 2-3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ë‹µ
    - ì¦‰ê°ì ì¸ ê°ì • ì¸ì‹ê³¼ ê³µê°
    - êµ¬ì²´ì ì´ê³  ì§ì ‘ì ì¸ ì§ˆë¬¸
    - ìœ„ê¸° ìƒí™© ì‹œ ì¦‰ì‹œ ëŒ€ì‘:
    * ê³µê°ì  ì‘ë‹µ
    * ì „ë¬¸ê°€ ì—°ê³„ ì •ë³´
    * ê°€ê¹Œìš´ ìƒë‹´ì„¼í„° ìë™ í‘œì‹œ
    * êµ¬ì²´ì  í–‰ë™ ì§€ì¹¨

    2. ë©€í‹°í„´ ì‘ë‹µ:
    - ìµœëŒ€ 4-5ë¬¸ì¥ê¹Œì§€ í—ˆìš©
    - ë‹¨ê³„ì  ë¬¸ì œ íƒìƒ‰:
    * ì´ˆê¸°: ê°œë°©í˜• ì§ˆë¬¸ìœ¼ë¡œ ìƒí™© íŒŒì•…
    * ì¤‘ê¸°: êµ¬ì²´ì  ìƒí™©ê³¼ ê°ì • íƒìƒ‰
    * í›„ê¸°: í•´ê²°ì±… ëª¨ìƒ‰ê³¼ ì‹¤ì²œ ë°©ì•ˆ ë…¼ì˜
    - ì´ì „ ëŒ€í™” ë‚´ìš© ì°¸ì¡°
    - ê°ì • ë³€í™” ì¶”ì  ë° ì–¸ê¸‰

    ìœ„ê¸° ìƒí™© ëŒ€ì‘ í˜•ì‹:
    ğŸš¨ ì „ë¬¸ê°€ì˜ ë„ì›€ì´ í•„ìš”í•´ ë³´ì…ë‹ˆë‹¤.

    ê¸´ê¸‰ ì—°ë½ì²˜:
    ğŸ“ ìì‚´ì˜ˆë°©ìƒë‹´ì „í™”: 1393
    ğŸ“ ì •ì‹ ê±´ê°•ìƒë‹´ì „í™”: 1577-0199

    ğŸ“ ê°€ê¹Œìš´ ìƒë‹´ì„¼í„°:
    [ìœ„ì¹˜ ê¸°ë°˜ ìƒë‹´ì„¼í„° ì •ë³´ ìë™ í‘œì‹œ]

    ëŒ€í™” ê¸°ë²•:
    1. ê°ì • ë°˜ì˜:
    - "~í•˜ì…”ì„œ ë§ì´ í˜ë“œì…¨ê² ë„¤ìš”"
    - "ê·¸ëŸ° ìƒí™©ì—ì„œ ê·¸ë ‡ê²Œ ëŠë¼ì‹œëŠ” ê²Œ ë‹¹ì—°í•©ë‹ˆë‹¤"

    2. ê°œë°©í˜• ì§ˆë¬¸:
    - "ì–´ë–¤ ì ì—ì„œ ê·¸ë ‡ê²Œ ëŠë¼ì‹œë‚˜ìš”?"
    - "êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ìƒí™©ì´ì—ˆë‚˜ìš”?"
    - "ê·¸ë™ì•ˆ ì–´ë–»ê²Œ ëŒ€ì²˜í•´ ì˜¤ì…¨ë‚˜ìš”?"

    ì£¼ì˜ì‚¬í•­:
    1. ì‘ë‹µ ê¸¸ì´ ì—„ê²© ê´€ë¦¬
    2. ì´ëª¨í‹°ì½˜ì€ ì²«/ë§ˆì§€ë§‰ ì¸ì‚¬ì™€ ì¢‹ì€ì¼, ê¸°ìœì¼, ìœ„ë¡œ í•„ìš”ì‹œì—ë§Œ ì‚¬ìš©
    3. ìœ„ê¸° ìƒí™© ì‹œ ì •í•´ì§„ í˜•ì‹ìœ¼ë¡œ ì¦‰ì‹œ ëŒ€ì‘
    4. ê°ì • ë³€í™”ë¥¼ í•­ìƒ ì¶”ì í•˜ê³  ì–¸ê¸‰
    5. ìƒë‹´ì„¼í„° ì •ë³´ëŠ” ìœ„ê¸° ìƒí™© ì‹œ ìë™ í¬í•¨

    ì°¸ê³ í•  ìƒë‹´ ì‚¬ë¡€:
    {context}

    í˜„ì¬ ëŒ€í™” ë§¥ë½ê³¼ ë‹¨ê³„ë¥¼ ê³ ë ¤í•˜ì—¬, ì‹±ê¸€í„´/ë©€í‹°í„´ ìƒí™©ì— ë§ëŠ” ì ì ˆí•œ ì‘ë‹µì„ ì œê³µí•˜ì„¸ìš”.
    ì‘ë‹µì€ ì§€ì •ëœ ê¸¸ì´ë¥¼ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ê³ , ìœ„ê¸° ìƒí™© ì‹œ ì •í•´ì§„ í˜•ì‹ì„ ë°˜ë“œì‹œ ë”°ë¥´ì„¸ìš”.
    """
            
            # ë©”ì‹œì§€ êµ¬ì„±
            messages = [
                {"role": "system", "content": system_prompt.format(context=context)}
            ]
            
            # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶”ê°€ (ìµœê·¼ 4ê°œ ë©”ì‹œì§€ë§Œ)
            recent_history = chat_history[-4:] if len(chat_history) > 4 else chat_history
            messages.extend(recent_history)
            
            # í˜„ì¬ ì§ˆë¬¸ ì¶”ê°€
            messages.append({"role": "user", "content": query})
            
            # GPT ì‘ë‹µ ìƒì„±
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages,
                temperature=0.3,
                max_tokens=500,  # ì§§ì€ ì‘ë‹µ ìœ ë„
                top_p=0.9,
                frequency_penalty=0.7,  # ë°˜ë³µ ì¤„ì´ê¸°
                presence_penalty=0.7    # ìƒˆë¡œìš´ ì£¼ì œ ë„ì… ì–µì œ
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            return f"ğŸ˜¥ ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            
            # ë©”ì‹œì§€ êµ¬ì„±
            messages = [
                {"role": "system", "content": system_prompt.format(context=context)}
            ]
            
            # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶”ê°€ (ìµœê·¼ 4ê°œ ë©”ì‹œì§€ë§Œ)
            recent_history = chat_history[-4:] if len(chat_history) > 4 else chat_history
            messages.extend(recent_history)
            
            # í˜„ì¬ ì§ˆë¬¸ ì¶”ê°€
            messages.append({"role": "user", "content": query})
            
            # GPT ì‘ë‹µ ìƒì„±
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages,
                temperature=0.3, 
                max_tokens=500,   
                top_p=0.9,
                frequency_penalty=0.6,  
                presence_penalty=0.6,   
            )
            return response.choices[0].message.content
            
        except Exception as e:
            return f"ğŸ˜¥ ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            
            # ë©”ì‹œì§€ êµ¬ì„±
            messages = [
                {"role": "system", "content": system_prompt.format(context=context)}
            ]
            
            # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶”ê°€ (ìµœê·¼ 3ê°œ ë©”ì‹œì§€ë§Œ)
            recent_history = chat_history[-3:] if len(chat_history) > 3 else chat_history
            messages.extend(recent_history)
            
            # í˜„ì¬ ì§ˆë¬¸ ì¶”ê°€
            messages.append({"role": "user", "content": query})
            
            # GPT ì‘ë‹µ ìƒì„±
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",  
                messages=messages,
                temperature=0.3,  
                max_tokens=500,   
                top_p=0.8,       
                frequency_penalty=0.3,
                presence_penalty=0.3,
            )
            return response.choices[0].message.content
            
        except Exception as e:
            return f"ğŸ˜¥ ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
